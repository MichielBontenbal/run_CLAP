{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97a13bc",
   "metadata": {},
   "source": [
    "# Visualising UrbanSoundsSamples with CLAP embeddings\n",
    "# WORK IN PROGRESS\n",
    "\n",
    "###  Goal of the notebook\n",
    "To visualise the UrbansSoundsSamples dataset with CLAP and PCA/t-SNE.\n",
    "\n",
    "### CLAP\n",
    "CLAP (Contrastive Language-Audio Pretraining) is a neural network trained on a variety of (audio, text) pairs. It can be instructed in to predict the most relevant text snippet, given an audio, without directly optimizing for the task.\n",
    "\n",
    "- Modelcard: https://huggingface.co/laion/larger_clap_general\n",
    "- CLAP paper: https://arxiv.org/abs/2211.06687\n",
    "- Reference: https://dataloop.ai/library/model/laion_larger_clap_music_and_speech/\n",
    "\n",
    "In this notebook we will use CLAP model: larger_clap_general\n",
    "\n",
    "### Using ðŸ¤— datasets and ðŸ¤—transformers\n",
    "The dataset is hosted on the Huggingface Hub at: https://huggingface.co/datasets/MichielBontenbal/UrbanSoundsII\n",
    "\n",
    "(This is a new version of the same dataset as the old dataset got corrupted.)\n",
    "\n",
    "This dataset contains nine classes of audio events in an urban environment. \n",
    "\n",
    "In this notebook we will use ðŸ¤—  ```dataset``` library to load this dataset. \n",
    "\n",
    "And we'll use the ðŸ¤— ```transformers``` library to run the CLAP model. Please find more info: https://huggingface.co/docs/transformers/model_doc/clap \n",
    "\n",
    "\n",
    "### Contents\n",
    "0. Install packages & check versions\n",
    "1. Inspection of dataset\n",
    "2. Get audio embeddings\n",
    "5. Get the labels \n",
    "6. PCA and t-SNE on the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d66e31",
   "metadata": {},
   "source": [
    "## 0. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca44ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24640679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc99f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80d4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install datasets\\[audio\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693f87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e18c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87dca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check python version\n",
    "import platform\n",
    "print(platform.python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95407312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f'numpy version: {np.__version__}')\n",
    "import soundfile\n",
    "print(f'soundfile version: {soundfile.__version__}')\n",
    "import librosa\n",
    "print(f'librosa version: {librosa.__version__}')\n",
    "import IPython\n",
    "print(f'IPython version: {IPython.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "print(f'datasets version: {datasets.__version__}')\n",
    "import transformers\n",
    "print(f'transformers version: {transformers.__version__}')\n",
    "import torch\n",
    "print(f'torch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4888e0",
   "metadata": {},
   "source": [
    "## 1. Inspection of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b91b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset =load_dataset(\"UrbanSounds/UrbanSoundsSamples\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deed307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the dataset\n",
    "#dataset = ds\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect one sample from \n",
    "example = dataset['audio'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612c868",
   "metadata": {},
   "source": [
    "You may notice that the audio column contains several features. Hereâ€™s what they are:\n",
    "\n",
    "- path: the path to the downloaded (and converted) audio file\n",
    "- array: The decoded audio data, represented as a 1-dimensional NumPy array.\n",
    "- sampling_rate. The sampling rate of the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb34b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting the audio array\n",
    "array = dataset[\"audio\"][0][\"array\"]\n",
    "sampling_rate = example[\"sampling_rate\"]\n",
    "print(array.shape)\n",
    "print(array)\n",
    "print(type(array))\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1deef",
   "metadata": {},
   "source": [
    "## 2. CLAP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2a85a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73d24d1f65a4efbaa7a5e13ebcd8795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import the dataset and define model, processor\n",
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "\n",
    "# Load the model and processor\n",
    "model = ClapModel.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
    "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
    "\n",
    "dataset =load_dataset(\"UrbanSounds/UrbanSoundsSamples\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85e5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an audio sample\n",
    "audio_sample_1 = dataset[0]\n",
    "\n",
    "# Preprocess the audio sample\n",
    "inputs_1 = processor(audios=audio_sample_1[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=48000)\n",
    "\n",
    "# Run the model\n",
    "audio_embedding_1 = model.get_audio_features(**inputs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba32308",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio_embedding_1.ndim)\n",
    "print(audio_embedding_1.shape)\n",
    "print(audio_embedding_1.dtype)\n",
    "print(type(audio_embedding_1))\n",
    "#print(audio_embedding_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f53e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same for another audio sample\n",
    "audio_sample_2 = dataset[0]\n",
    "inputs_2 = processor(audios=audio_sample_2[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=48000)\n",
    "audio_embedding_2 = model.get_audio_features(**inputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to get all the audio embeddings and store them as individual .pt files\n",
    "def get_audio_embeddings(i):\n",
    "    global embedding\n",
    "    # Preprocess and encode the first image\n",
    "    sample = dataset[i]\n",
    "    inputs = processor(audios=sample[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=48000)\n",
    "    embedding = model.get_audio_features(**inputs)\n",
    "    torch.save(embedding, 'embedding'+str(i)+'.pt')\n",
    "    return embedding\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    get_audio_embeddings(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eac6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all audio embeddings into a python dict\n",
    "import glob\n",
    "embeddings_files = glob.glob('*.pt')\n",
    "\n",
    "#load all files as embeddings\n",
    "embeddings_list=[]\n",
    "for i in range(len(embeddings_files)):\n",
    "    embeddings_list.append(torch.load('embedding'+str(1)+'.pt'))\n",
    "\n",
    "embeddings_dict = dict(enumerate(embeddings_list))\n",
    "#embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing an example to check it\n",
    "embeddings_dict[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2619e2",
   "metadata": {},
   "source": [
    "## 3. Calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da86f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddding_1 = torch.load('embedding1.pt')\n",
    "#audio_embedding_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bba03e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddding_2 = torch.load('embedding2.pt')\n",
    "#audio_embedding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab114e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = torch.nn.functional.cosine_similarity(audio_embedding_1, audio_embedding_2, dim=1)\n",
    "\n",
    "print(f\"Cosine Similarity: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15839bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the result by listening to it\n",
    "import IPython\n",
    "print(f'Audio sample 1:')\n",
    "IPython.display.Audio(audio_sample_1['audio']['array'], rate=example['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5aae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Audio sample 2:')\n",
    "IPython.display.Audio(audio_sample_2['audio']['array'], rate=example['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42402ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random number to select from dataset\n",
    "import random\n",
    "\n",
    "random_number_1 = random.randint(0, len(dataset['audio']))\n",
    "random_number_2 = random.randint(0, len(dataset['audio']))\n",
    "print(f'First example: {random_number_1}')\n",
    "print(f'Second example: {random_number_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304d2e8",
   "metadata": {},
   "source": [
    "## 5. Get the labels\n",
    "Huggingface does not give you the option to name the labels in the dataset.\n",
    "So we will run some code to get the right label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4171af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is code to convert the given labels (0,1,2,3,4,5,6,7,8) to a real string. \n",
    "# create a dictionary the converts the class folders to real names\n",
    "label_dict ={0:'Gunshot', 1:'Moped alarm', 2:'Moped', 3:'Claxon', 4:'Slamming door', 5:'Screaming', 6:'Motorcycle', 7:'Talking', 8:'Music'}\n",
    "print('The given labels are: ')\n",
    "for i in range(0,9):\n",
    "    print(label_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b50a27",
   "metadata": {},
   "source": [
    "## 6. Visualise the embeddings with PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9239fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to get all the audio embeddings in numpy format\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_audio_embeddings_np(i):\n",
    "    global embedding_np\n",
    "    # Preprocess and encode the first image\n",
    "    sample = dataset[i]\n",
    "    inputs = processor(audios=sample[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=48000)\n",
    "    embedding = model.get_audio_features(**inputs)\n",
    "    \n",
    "    embedding_np = np.array(embedding.detach().cpu().numpy())\n",
    "    return embedding_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ef5299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 512)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "#Create an array with all the audio embeddings (array of arrays)\n",
    "combined_array = np.empty((0, 512))\n",
    "\n",
    "for i in range(len(dataset)-1):\n",
    "   get_audio_embeddings_np(i) \n",
    "   combined_array = np.vstack((combined_array, embedding_np))\n",
    "   #print(combined_array.shape)\n",
    "\n",
    "#Check the shape of the array and items in the array\n",
    "print(combined_array.shape)\n",
    "print(combined_array[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dbac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the embeddings\n",
    "embeddings_np = combined_array / np.linalg.norm(combined_array, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f928fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Apply PCA to reduce dimensions (optional)\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for faster t-SNE\n",
    "embeddings_pca = pca.fit_transform(embeddings_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4100a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Apply t-SNE to reduce to 2D for visualization\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(embeddings_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8122df61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(228,26,28)",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -1.5650612,
          -1.5896049,
          -1.9105129,
          -1.9377657,
          -0.61854607,
          -1.2473736,
          -1.2496306,
          -1.9022895,
          -1.683807,
          -1.9150693,
          -1.8979867,
          -1.9545052,
          -0.74117297,
          -1.4871486,
          -2.3324616,
          -0.94443303,
          -1.2420983,
          -1.1413476,
          -1.3112797,
          -1.3938227,
          0.819792,
          0.87742037,
          -0.060255505,
          0.53725594,
          -0.21612987,
          1.7672933,
          0.5112157,
          1.5577041,
          0.9069508,
          0.58182126,
          1.3512677,
          0.14552942,
          0.5774531,
          0.63720614,
          0.6471949,
          -0.31870952,
          0.24341045,
          1.1961492,
          0.4139524,
          1.6951838,
          0.8783769,
          0.16800995,
          1.6593362,
          1.7196718,
          0.0052438825,
          0.10915476,
          1.9506706,
          0.12876514,
          1.4126647
         ],
         "xaxis": "x",
         "y": [
          -3.0393662,
          -1.897609,
          -0.5837377,
          -2.2633266,
          -3.4497008,
          0.63880926,
          0.7825345,
          -0.8823831,
          0.29080114,
          -1.1088536,
          -1.5473634,
          -1.8820133,
          -3.1160157,
          -1.8957052,
          -1.4270164,
          0.62033135,
          0.60296845,
          -0.3798002,
          -1.1395429,
          -1.3180294,
          -0.2441828,
          -2.5624824,
          -0.46816432,
          -1.6165713,
          -0.42506757,
          -1.9675201,
          0.347162,
          -2.2361841,
          -0.16087879,
          -0.15203,
          -0.7351006,
          -1.7311915,
          -2.3742,
          -2.5515203,
          -3.3564544,
          -2.5884798,
          -3.0087287,
          -3.5598316,
          -2.5065768,
          -3.3732154,
          -2.977472,
          -1.5297734,
          -2.7595954,
          -3.8048818,
          -2.2172046,
          -3.3539197,
          -3.3907218,
          -2.3124967,
          -2.8177764
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Visualization of Urban Sounds dataset using CLAP embeddings and t-SNE"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have a list of class labels corresponding to each point\n",
    "# If you don't have this, you'll need to create it based on your data\n",
    "#class_labels = labelnames_list  # Your list of class labels here, should be same length as embeddings_2d\n",
    "\n",
    "# Create a color map for the 9 classes\n",
    "color_map = px.colors.qualitative.Set1[:9]\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=embeddings_2d[:, 0],\n",
    "    y=embeddings_2d[:, 1],\n",
    "    #color=class_labels,\n",
    "    color_discrete_sequence=color_map,\n",
    "    opacity=0.7,\n",
    "    title='Visualization of Urban Sounds dataset using CLAP embeddings and t-SNE',\n",
    "    #labels={'color': 'Class'}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec7971",
   "metadata": {},
   "source": [
    "##  Manually labeling the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d7c7bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/x-wav;bas